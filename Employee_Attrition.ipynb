{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshithasmj/Employee-Attrition/blob/main/Employee_Attrition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introduction**\n",
        "Employee attrition (when employees leave the company) can be costly, both in terms of productivity and recruitment expenses. By leveraging machine learning techniques, the goal is to identify patterns in employee data that predict whether an employee is likely to leave or stay.\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "Build a predictive model that helps HR professionals understand what drives employee retention and how to reduce attrition in the organization."
      ],
      "metadata": {
        "id": "CjVgL6M1DDnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Dataset Source**\n",
        "\n",
        "   - https://www.kaggle.com/datasets/patelprashant/employee-attrition/data"
      ],
      "metadata": {
        "id": "w01ks2Ft0oPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGmu7TnUCzlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110677de-8a22-4007-a603-a45a9817b1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphviz\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geOscVHCL6dO"
      },
      "source": [
        "## **Load Data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_WQobjbDCuj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1c9f41ba-b02a-4141-fba5-ecc2a1de0332"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'employee_attrition.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-995065226.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employee_attrition.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'employee_attrition.csv'"
          ]
        }
      ],
      "source": [
        "emp = pd.read_csv(\"employee_attrition.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP3Ah1UILIYO"
      },
      "outputs": [],
      "source": [
        "attrition = emp['Attrition'].value_counts()\n",
        "print(attrition)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   This is an imbalanced dataset as 237/1233 or the ratio of yes to no is a low percentage or ratio.\n",
        "*   Some challenges of class imablance can be bis to the majority class, inadequate resutls on the minority class, and missing cases.\n",
        "*   Some ways to handle these issues can be to undersample, oversample, adjust the weight classes, or consider the class with lower distribution as the anomaly.\n"
      ],
      "metadata": {
        "id": "etKu6Plo8vRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph the Age Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(emp['Age'], kde=True, bins=30, color=\"blue\")\n",
        "plt.title(\"Age Distribution\")\n",
        "plt.xlabel(\"Age (in years)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X0CWaa8t4XNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph Monthly Income\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(emp[\"MonthlyIncome\"], kde = True, bins=30, color=\"green\")\n",
        "plt.title(\"Monthly Income Distribution\")\n",
        "plt.xlabel(\"Monthly Income\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d3_oMMjm4nVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(emp)"
      ],
      "metadata": {
        "id": "m9YKbbMkAVUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm_WbzYXskGu"
      },
      "outputs": [],
      "source": [
        "#Extracting feature columns\n",
        "df_features = emp.drop(columns=[\"Attrition\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpbYtjJfrEUu"
      },
      "outputs": [],
      "source": [
        "#extracting target column from dataset\n",
        "df_target = emp[['Attrition']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_features.head(5))\n",
        "print(df_target.head(5))"
      ],
      "metadata": {
        "id": "YnfKOVVMAuNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxOWBdU0YjWE"
      },
      "outputs": [],
      "source": [
        "categorical_variables = df_features.select_dtypes(exclude=['numeric'])\n",
        "categorical_variables.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = df_target.squeeze()\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "m0z-iMJrePQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "GVZh_ni1hwBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW_yhiOELBWl"
      },
      "outputs": [],
      "source": [
        "#Using gini impurity measure\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
        "clf = DecrisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "clf.fit(X_train_encoded, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hECiXz6UNucG"
      },
      "outputs": [],
      "source": [
        "#Visualise the decision tree\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(clf, filled=True, feature_names=X_train_encoded.columns, class_names=np.unique(y_train))\n",
        "plt.title(\"Decision Tree Classifier\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To reach the leftmmost leaf mode, overtime == \"Yes\" would be True would be the first step to the left subtree. If TotalWorkingYears <= 1.5 is True, it goes left. If BusinessTravek_Travel_Frequently <= 0.5 is True, it goes on to left again. It will reach the last leaf node as Class = \"No\" which predicts that the employee will stay. Therefore, employees who work overtime, have less than one and a half years of total experiences, and do not travel much are more likely to stay with the company."
      ],
      "metadata": {
        "id": "PZfE3OvCqbx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENBHOBu5aCd3"
      },
      "outputs": [],
      "source": [
        "#One hot encode categorical data\n",
        "X_test_encoded = pd.get_dummies(X_test)\n",
        "X_test_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "categorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoder.fit(X_train[categorical_cols])\n",
        "\n",
        "X_train_encoded = encoder.transform(X_train[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "\n",
        "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
        "X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
        "X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)\n",
        "\n",
        "X_train_full = pd.concat([X_train.drop(columns=categorical_cols), X_train_encoded], axis=1)\n",
        "X_test_full = pd.concat([X_test.drop(columns=categorical_cols), X_test_encoded], axis=1)\n",
        "\n",
        "X_test_full = X_test_full.reindex(columns=X_train_full.columns, fill_value=0)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train_full, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_full)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "random_instance_index = random.randint(0, len(X_test_full) - 1)\n",
        "random_instance = X_test_full.iloc[random_instance_index, :].to_frame().T\n",
        "\n",
        "prediction = clf.predict(random_instance)\n",
        "print(f\"Prediction for the selected instance: {prediction[0]}\")\n",
        "\n",
        "# Visualize the prediction node path\n",
        "node_indicator = clf.decision_path(random_instance)\n",
        "\n",
        "# Get the indices of the nodes visited along the decision path\n",
        "node_indices = node_indicator.indices\n",
        "\n",
        "# Extract the node names and conditions for the decision path\n",
        "decision_path_info = []\n",
        "\n",
        "for node_index in node_indices:\n",
        "    feature_index = clf.tree_.feature[node_index]\n",
        "\n",
        "    if feature_index != -2:\n",
        "        feature_name = X_train_full.columns[feature_index]\n",
        "        threshold = clf.tree_.threshold[node_index]\n",
        "        decision_path_info.append((node_index, feature_name, threshold))\n",
        "\n",
        "for node_index, feature_name, threshold in decision_path_info:\n",
        "    print(f\"Node {node_index}: Feature '{feature_name}' <= {threshold}\")\n"
      ],
      "metadata": {
        "id": "aQm57uBobV5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUML5W9Bt3Sk"
      },
      "outputs": [],
      "source": [
        "#compare the model's predictions against the actual target values in the test dataset with accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = clf.predict(X_test_full)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "OgbNZJljzi4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize = (8,6))\n",
        "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=clf.classes_, yticklabels=clf.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "51CZDY4VcNyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A: This confusion matrix represents the performance of a classification model with two classes: Yes and No. The matrix in clock-wise order was true negative, false positives, true positives, and false negatives. 220 were correctly predicted \"No\", 35 were wrongly predicted \"Yes\" when the actual answer was \"No\", 9 were correctly predicted as \"Yes\", and 30 were predicted \"No\" when it was \"No\".\n",
        "\n",
        "B: The false positives mean that the attrition would be wrongly predicted when employees plan on staying. This may mean that resources and company time would be used to combat the reprussions of the the expected untrue attrition. Not correctly finding the employees that are at attrition cause the company to lose money.\n",
        "\n",
        "C: A confusion matrix indicates if there is a more of a Type 1 or Type 2 error and other results that may be more insightful for evaluation. Accuracy may not work for this situation as this is an unbalanced dataset. Therefore, confusion matrix works better.\n",
        "\n",
        "D: Some improvements can be trying different models such as Logistic Regression and adjust the decision threshold to hopefully reduce false negatives."
      ],
      "metadata": {
        "id": "S7kKtJiotDDA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "default"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}